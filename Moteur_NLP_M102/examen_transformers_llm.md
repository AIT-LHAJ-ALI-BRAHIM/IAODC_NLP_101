# Examen : Manipulation des Transformers et Exploration des LLM
## Niveau : D√©butant

**Dur√©e sugg√©r√©e :** 3 heures  
**Note totale :** 100 points

---

## Partie 1 : Questions Th√©oriques (30 points)

### Question 1 (5 points)
Expliquez en vos propres mots ce qu'est un mod√®le Transformer et quelle innovation majeure il apporte par rapport aux architectures pr√©c√©dentes (RNN, LSTM).

### Question 2 (5 points)
Qu'est-ce que le m√©canisme d'attention (attention mechanism) ? Pourquoi est-il crucial dans l'architecture Transformer ?

### Question 3 (5 points)
D√©finissez les termes suivants :
- **Token**
- **Embedding**
- **Context window**
- **Temperature**
- **Top-k sampling**

### Question 4 (5 points)
Quelle est la diff√©rence entre :
- Un mod√®le encoder-only (comme BERT)
- Un mod√®le decoder-only (comme GPT)
- Un mod√®le encoder-decoder (comme T5)

Donnez un exemple d'usage pour chacun.

### Question 5 (10 points)
Expliquez le processus de pr√©-entra√Ænement et de fine-tuning d'un LLM. Pourquoi ces deux √©tapes sont-elles importantes ?

---

## Partie 2 : Manipulation Pratique avec Hugging Face (40 points)

### Exercice 1 : Chargement et utilisation d'un mod√®le (15 points)

√âcrivez un script Python qui :
1. Charge le mod√®le `distilbert-base-uncased-finetuned-sst-2-english`
2. Analyse le sentiment des phrases suivantes :
   - "I love this movie, it's amazing!"
   - "This product is terrible and broken."
   - "The weather is okay today."
3. Affiche les r√©sultats avec les scores de confiance

**Biblioth√®ques autoris√©es :** transformers, torch

### Exercice 2 : G√©n√©ration de texte (15 points)

Cr√©ez un script qui :
1. Charge le mod√®le `gpt2`
2. G√©n√®re du texte √† partir du prompt : "Once upon a time in a magical forest,"
3. Exp√©rimente avec diff√©rents param√®tres :
   - `temperature` : 0.7, puis 1.5
   - `max_length` : 50, puis 100
   - `top_k` : 50
4. Compare et commente les r√©sultats obtenus avec diff√©rentes temp√©ratures

### Exercice 3 : Tokenization (10 points)

√âcrivez un code qui :
1. Charge le tokenizer de `bert-base-uncased`
2. Tokenise la phrase : "Transformers are revolutionizing natural language processing!"
3. Affiche :
   - Les tokens
   - Les IDs des tokens
   - Le texte d√©cod√© √† partir des IDs
4. Expliquez ce qui se passe avec les mots compos√©s ou inconnus

---

## Partie 3 : Exploration et Analyse (20 points)

### Exercice 4 : Comparaison de mod√®les (10 points)

Comparez les performances de deux mod√®les diff√©rents sur la m√™me t√¢che de question-r√©ponse :
- `distilbert-base-cased-distilled-squad`
- `bert-large-uncased-whole-word-masking-finetuned-squad`

**Contexte :** "The Eiffel Tower is located in Paris, France. It was completed in 1889 and stands 330 meters tall."

**Questions :**
1. "Where is the Eiffel Tower located?"
2. "When was it completed?"
3. "How tall is the Eiffel Tower?"

Analysez :
- La pr√©cision des r√©ponses
- Le temps d'inf√©rence
- Les scores de confiance

### Exercice 5 : Prompt Engineering (10 points)

Pour la t√¢che de g√©n√©ration de texte, testez diff√©rents prompts pour obtenir :
1. Un po√®me sur l'intelligence artificielle
2. Une explication technique du machine learning
3. Une recette de cuisine

Documentez :
- Les prompts utilis√©s
- Les r√©sultats obtenus
- Les ajustements n√©cessaires pour am√©liorer la sortie

---

## Partie 4 : Mini-Projet (10 points)

### Projet : Classificateur de sentiment personnalis√©

Cr√©ez une petite application qui :
1. Prend en entr√©e un texte de l'utilisateur
2. Utilise un mod√®le de votre choix pour analyser le sentiment
3. Affiche le r√©sultat de mani√®re conviviale
4. Permet de traiter plusieurs textes successivement

**Bonus (+5 points) :** Ajoutez une interface simple avec Gradio ou Streamlit

---

## Crit√®res d'√©valuation

### Code (50%)
- Fonctionnalit√© : Le code s'ex√©cute sans erreur
- Qualit√© : Code propre, comment√©, bien structur√©
- Utilisation correcte des biblioth√®ques

### Compr√©hension th√©orique (30%)
- Pr√©cision des r√©ponses
- Clart√© des explications
- Utilisation appropri√©e du vocabulaire technique

### Analyse et r√©flexion (20%)
- Profondeur de l'analyse
- Pertinence des observations
- Esprit critique

---

## Ressources autoris√©es

- Documentation officielle de Hugging Face : https://huggingface.co/docs
- Documentation PyTorch/TensorFlow
- Vos notes de cours

**‚ö†Ô∏è Important :** Le plagiat de code trouv√© en ligne sans compr√©hension est sanctionn√©. Vous devez √™tre capable d'expliquer chaque ligne de votre code.

---

## Bar√®me d√©taill√©

| Partie | Points | Description |
|--------|--------|-------------|
| Partie 1 | 30 | Questions th√©oriques |
| Partie 2 | 40 | Manipulation pratique |
| Partie 3 | 20 | Exploration et analyse |
| Partie 4 | 10 | Mini-projet |
| **Total** | **100** | |
| Bonus | +5 | Interface utilisateur |

---

## Conseils pour r√©ussir

1. **Lisez attentivement** chaque question avant de commencer
2. **Testez votre code** r√©guli√®rement
3. **Commentez** votre code pour montrer votre compr√©hension
4. **G√©rez votre temps** : ne restez pas bloqu√© trop longtemps sur une question
5. **V√©rifiez** vos r√©ponses avant de soumettre

**Bonne chance ! üöÄ**
